# PAC-MCL Configuration - ConvNeXt Tiny

# Model configuration
model:
  backbone_name: "convnext_tiny"
  num_classes: 80
  pretrained: true
  freeze_backbone: false
  
  # Part extraction parameters
  num_parts: 6
  part_dim: 64
  use_adaptive_parts: false
  
  # Manifold parameters
  distance_metric: "log_euclidean"
  alignment_method: "bnn"
  shrinkage_alpha: null
  eps: 0.1e-4
  
  # Loss parameters
  gamma: 0.5
  lambda_pos_ce: 1.0
  margin: 0.2

# Data configuration
data:
  dataset_name: "soybean"
  data_root: "./data"
  image_size: 224
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# Training configuration
training:
  epochs: 150
  batch_size: 24  # Smaller batch for ConvNeXt
  num_workers: 4
  dual_view: true
  
  # Optimizer
  optimizer: "adamw"
  learning_rate: 0.2e-4
  weight_decay: 0.05
  
  # Learning rate scheduler
  scheduler:
    type: "warmup_cosine"
    params:
      warmup_epochs: 10
      max_epochs: 150
      eta_min: 0.1e-6
  
  # Early stopping
  early_stopping:
    patience: 20
    min_delta: 0.1e-4
  
  # Output
  output_dir: "./outputs/soybean_convnext_pac_mcl"

# Experimental settings
experiment:
  name: "PAC_MCL_Soybean_ConvNeXt"
  description: "PAC-MCL training on Soybean dataset with ConvNeXt-Tiny backbone"
  tags: ["pac-mcl", "soybean", "convnext", "manifold-learning"]
  
  curriculum:
    enable: true
    switch_epoch: 80
    switch_metric: "bures_wasserstein"
